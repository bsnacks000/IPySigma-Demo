{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pull from ADS\n",
    "Focusing in on 50 most highly cited astronomy papers from the last 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import ads as ads \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from networkx.algorithms import bipartite as bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"ADS_DEV_KEY\"] = \"kNUoTurJ5TXV9hsw9KQN1k8wH4U0D7Oy0CJoOvyw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ads.config.token = 'ADS_DEV_KEY' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for papers \n",
    "# 50 most cited papers recent papers\n",
    "papers1 = list(ads.SearchQuery(q=\"*\",\n",
    "                               sort=\"citation_count desc\",\n",
    "                               year=\"2012, 2013, 2014, 2015, 2016, 2017\",\n",
    "                               rows=50 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find author names\n",
    "a = []\n",
    "for i in papers1:\n",
    "    authors1 = i.author\n",
    "    a.append(authors1)\n",
    "author_names = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsnacks/Py_projects/ipysigma_demo/venv/lib/python2.7/site-packages/ads/utils.py:31: UserWarning: You are lazy loading attributes via 'pub', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# find the journals\n",
    "j = []\n",
    "for i in papers1:\n",
    "    journals1 = i.pub\n",
    "    j.append(journals1)\n",
    "journals = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find year of publication\n",
    "y = []\n",
    "for i in papers1:\n",
    "    year1 = i.year\n",
    "    y.append(year1)\n",
    "year = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find titles\n",
    "t = []\n",
    "for i in papers1:\n",
    "    title1 = i.title\n",
    "    t.append(title1)\n",
    "title = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsnacks/Py_projects/ipysigma_demo/venv/lib/python2.7/site-packages/ads/utils.py:31: UserWarning: You are lazy loading attributes via 'keyword', and so are making multiple calls to the API. This will impact your overall rate limits.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# find keywords\n",
    "k = []\n",
    "for i in papers1:\n",
    "    keyword1 = i.keyword\n",
    "    k.append(keyword1)\n",
    "keyword = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an initial df\n",
    "df = pd.DataFrame({'Author_Names' : author_names,\n",
    "                   'Journal':journals,\n",
    "                   'Year':year,\n",
    "                   'Title':title,\n",
    "                   'Keyword':keyword\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34752, 5)\n"
     ]
    }
   ],
   "source": [
    "# Expand the df with melt\n",
    "s1 = df.apply(lambda x: pd.Series(x['Author_Names']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s1.name = 'Author_Name'\n",
    "s2 = df.apply(lambda x: pd.Series(x['Title']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s2.name = 'Title'\n",
    "s3 = df.apply(lambda x: pd.Series(x['Keyword']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s3.name = 'Keyword'\n",
    "df_m = df.drop(['Author_Names','Title', 'Keyword'], axis=1).join(s1)\n",
    "df_m = df_m.join(s2)\n",
    "df_m = df_m.join(s3)\n",
    "\n",
    "print df_m.shapeG.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.to_csv('top_50.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.from_pandas_dataframe(df_m, 'Journal', 'Author_Name', ['Title', 'Year', 'Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ca8205641389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ma_proj_sg_largest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_projected_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msg_largest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAuthor_Names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj_proj_sg_largest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_proj_sg_largest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsnacks/Py_projects/ipysigma_demo/venv/lib/python2.7/site-packages/networkx/classes/graph.pyc\u001b[0m in \u001b[0;36medges\u001b[0;34m(self, nbunch, data, default)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0medges_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbunch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bsnacks/Py_projects/ipysigma_demo/venv/lib/python2.7/site-packages/networkx/classes/graph.pyc\u001b[0m in \u001b[0;36medges_iter\u001b[0;34m(self, nbunch, data, default)\u001b[0m\n\u001b[1;32m   1196\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mnbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnbr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m                 \u001b[0mseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Weighted Projections/Clustering\n",
    "# Largest most connected graph - 200 cut-off \n",
    "big_subg = [i for i in nx.connected_component_subgraphs(G) if len(i) > 200]\n",
    "# Largest:\n",
    "sg_largest = big_subg[0] # largest connected subgraph\n",
    "\n",
    "# weighted_projections applied to subgraph to separate the two components\n",
    "Journals,Author_Names = bi.sets(sg_largest)  # split into bipartites\n",
    "j_proj_sg_largest = bi.weighted_projected_graph(sg_largest, Journals) \n",
    "a_proj_sg_largest = bi.weighted_projected_graph(sg_largest, Author_Names)\n",
    "\n",
    "j = j_proj_sg_largest.edges(data=True) \n",
    "a = a_proj_sg_largest.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Island Method \n",
    "def trim(g):\n",
    "    g_temp = nx.Graph()\n",
    "    edge_bunch = [i for i in g.edges(data=True)]    \n",
    "    g_temp.add_edges_from(edge_bunch)\n",
    "    return g_temp\n",
    "a_sg_island =  trim(a_proj_sg_largest)\n",
    "j_sg_island = trim(j_proj_sg_largest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centrality\n",
    "a_degree = nx.degree_centrality(a_sg_island)\n",
    "j_degree = nx.degree_centrality(j_sg_island)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print a_sg_island.number_of_nodes()\n",
    "print j_sg_island.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(a_degree) # 12 journals\n",
    "a_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(j_degree) # 7268 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nx.draw(a_sg_island,pos=nx.spring_layout(a_sg_island)) # use spring layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(j_sg_island,pos=nx.spring_layout(j_sg_island)) # use spring layout"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
